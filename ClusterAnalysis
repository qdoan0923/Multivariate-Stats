

# "Cluster Analysis"	
# "JDRS"	
# "Multivariate"	


# ##  Cluster Analysis in R 	
# ###  J. Reuning-Scherer	


# ###  Faces and Stars	

# Here are two whimsical techniques that work well for small numbers of observation and variables.	

# First, load some relevant packages for cluster analysis.	

par(ask=FALSE)	
#load relevant libraries	
library(aplpack)	
library(fpc)	
library(cluster)	
library(ape)	
library(amap)	

# ###Example Five - Endangered Species Data	


#get data	
WB <- read.csv("/Users/quintdoan/Documents/Yale/Spring 2021/Multivariate/Edited_Data.csv", header = T, as.is = F)	

#We need complete cases for code to work	
WB<- WB[complete.cases(WB), ]	
dim(WB)

#Get sample of 100 species
WB<-WB[sample(nrow(WB), 100), ]
dim(WB)

# I used a data imputation program to make sure that all species had values for all variables
# As a result, some categorical variables, such as activity cycle, were made continous.
# Here, I make the variables categorical again by rounding to the nearest whole number
WB$ActivityCycle<-round(WB$X1.1_ActivityCycle)
#Create a column that shows if something is extinct or endangered
WB$Extinct2=2*(WB$Extinct)
#Create a column that shows if something is extinct or endangered
#There is not enough of these points to define a 12 dimensional space
WB$Extinct_Endangered=(WB$Extinct2+WB$IUCN_LISTED)
# Only one point that was both endangered and now extinct, delete
#delete datapoints that are both extinct and listed as endangered
WB <- WB[WB$Extinct_Endangered != 3,]

#Make a column that shows both the activity cycle and conservation status
WB$ActivityCycleLetter <- chartr("123456789", "ABCDEFGHI", WB$ActivityCycle)
WB$ExtinctEndangeredLetter <- chartr("012345678", "ABCDEFGHI", WB$Extinct_Endangered)
WB$LetterCombo<- with(WB, paste0(ActivityCycleLetter,ExtinctEndangeredLetter))

###  First we do Clustering of Plots	
#get long version of species columns labels	
WB.lab <- WB$Labels	
#WB<- NASA[, -48]	
head(WB)	

#standardize data	
WBscale <- scale(WB[, 2:48])	
rownames(WBscale) <- as.factor(WB$Species_Name)	

#Get plot for Euclidean, Ward. D.

#get the distance matrix	
dist1 <- dist(WBscale, method = "euclidean")	

#now do clustering use WARDs method	
clust1 <- hclust(dist1, method = "ward.D")	

#draw the dendrogram	
plot(clust1,labels = WB[, 1], cex = 0.5, xlab = "Species (Euclidean, Ward.D)", ylab = "Distance", main = "Clustering for Mammal Species Data")	
#rect.hclust(clust1, k = 5)	

#Get plot for Jaccard, Ward. D.
#for other distance metrics, use the VEGAN package	
library(vegan) 

#get the distance matrix	
dist1 <- vegdist(WBscale, method = "jaccard", upper = T)	

#now do clustering use WARDs method	
clust1 <- hclust(dist1, method = "ward.D")	

#draw the dendrogram	
plot(clust1,labels = WB[, 1], cex = 0.5, xlab = "Species (Jaccard, Ward.D)", ylab = "Distance", main = "Clustering for Mammal Species Data")	

#Get plot for Euclidean, Centroid

#get the distance matrix	
dist1 <- dist(WBscale, method = "euclidean")	

#now do clustering use WARDs method	
clust1 <- hclust(dist1, method = "centroid")	

#draw the dendrogram	
plot(clust1,labels = WB[, 1], cex = 0.5, xlab = "Species (Euclidean, Centroid)", ylab = "Distance", main = "Clustering for Mammal Species Data")	

#Get plot for Jaccard, Centroid

#get the distance matrix	
dist1 <- vegdist(WBscale, method = "jaccard", upper = T)	

#now do clustering use WARDs method	
clust1 <- hclust(dist1, method = "centroid")	

#draw the dendrogram	
plot(clust1,labels = WB[, 1], cex = 0.5, xlab = "Species (Jaccard, Centroid)", ylab = "Distance", main = "Clustering for Mammal Species Data")	


# Get membership and evaluate number of clusters.	

#Get plot for Euclidean, Ward. D again because it is the best

#get the distance matrix	
dist1 <- dist(WBscale, method = "euclidean")	

#now do clustering use WARDs method	
clust1 <- hclust(dist1, method = "ward.D")	

#draw the dendrogram	
plot(clust1,labels = WB[, 1], cex = 0.5, xlab = "Species (Euclidean, Ward.D)", ylab = "Distance", main = "Clustering for Mammal Species Data")	
#rect.hclust(clust1, k = 5)	

#get membership vector (which plot is in which group)	
cuts <- cutree(clust1, k = 5)	
cuts	
# ####Evaluate Number of Clusters	

# We can use the online code to calculate 'number of clusters' metrics.  Note this ONLY works for normalized data.	


source("http://reuningscherer.net/multivariate/R/HClusEval3.R.txt")	
hclus_eval(WBscale, dist_m = 'euclidean', clus_m = 'ward', plot_op = T)	


# Now do same analysis, but using Jaccard distance	


#for other distance metrics, use the VEGAN package	
library(vegan)	

#get the distance matrix	
dist1 <- vegdist(WB[, 2:48], method = "jaccard", upper = T)	

#now do clustering - use WARDs method	
clust1 <- hclust(dist1, method = "ward.D")	

#draw the dendrogram	
plot(clust1,labels = WB[, 1], cex = 0.5, xlab = "Species (Jaccard, Ward.D)", ylab = "Distance", main = "Clustering for Mammal Species Data")	
rect.hclust(clust1, k = 2)	

#get membership vector (which species is in which group)	
cuts <- cutree(clust1, k = 2)	
cuts	

#Make plot of two cluster solution in space desginated by first two principal components	

clusplot(WB, cuts, color = TRUE, shade = TRUE, labels = 2 , lines = 0,	
         main = "Mammal Species Two Cluster Plot, Ward's Method, First two PC")	

#Make plot of two cluster solution in space desginated by first two	
#  two discriminant functions	

plotcluster(WB[,2:48], cuts, main = "Two Cluster Solution in DA Space",	
            xlab = "First Discriminant Function", ylab = "Second Discriminant Function")	


# Finally, we do clustering of the VARIABLES (i.e. the traits and habitat features)	


#transpose data	
WBtrans <- t(WBscale)	

#get the distance matrix	
dist1 <- dist(WBtrans, method = "minkowski", p = 3)	

#now do clustering use centroid method	
clust1 <- hclust(dist1, method = "complete")	

#draw the dendrogram 	
plot(clust1, labels = WB.lab[2:48], cex = .9, xlab = "", ylab = "Distance", main = "Clustering for Species Data")	
rect.hclust(clust1, k = 2)	

#get membership vector (which species is in which group)	
cuts <- cutree(clust1, k = 2)	
cuts 	

#Evaluate Number of Clusters	
hclus_eval(WBtrans, dist_m = 'euclidean', clus_m = 'ward', plot_op = T)	


# Other ideas for the species data:	

# See what happens if you dont' scale the variables	
# Convert data to presence/absence and use binary metrics (options in vegdist or designdist)	


# ##  K-means Clustering - Endangered Species Data


#Just try six clusters to see how this works	
#  Centers gives the number of clusters desired.  	
#  You can either give a vector with the original centers, OR just specify the number of clusters.	
km1 <- kmeans(WBscale, centers = 6)	
km1	

#see which Species are in each cluster	
for (i in 1:6){	
  print(paste("Species in Cluster ", i))	
  print(WB$Species_Name[km1$cluster == i])	
  print (" ")	
}	


# ### Modified Script by [Matt Peeples](https://github.com/mpeeples2008/Kmeans)	

# Produces screeplot like diagram with randomized comparison based on randomization within columns (i.e. as if points had been randomly assigned data values, one from each column.  Keeps total internal SS the same.	


#kdata is just normalized input dataset	
kdata <- WBscale	
n.lev <- 15  #set max value for number of clusters k	

# Calculate the within groups sum of squared error (SSE) for the number of cluster solutions selected by the user	
wss <- rnorm(10)	
while (prod(wss==sort(wss,decreasing=T))==0) {	
  wss <- (nrow(kdata)-1)*sum(apply(kdata,2,var))	
  for (i in 2:n.lev) wss[i] <- sum(kmeans(kdata, centers=i, iter.max=30)$withinss)}	

# Calculate the within groups SSE for 250 randomized data sets (based on the original input data)	
k.rand <- function(x){	
  km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])	
  rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))	
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)	
  rand.wss <- as.matrix(rand.wss)	
  return(rand.wss)	
}	

rand.mat <- matrix(0,n.lev,250)	

k.1 <- function(x) { 	
  for (i in 1:250) {	
    r.mat <- as.matrix(suppressWarnings(k.rand(kdata)))	
    rand.mat[,i] <- r.mat}	
  return(rand.mat)	
}	

# Same function as above for data with < 3 column variables	
k.2.rand <- function(x){	
  rand.mat <- matrix(0,n.lev,250)	
  km.rand <- matrix(sample(x),dim(x)[1],dim(x)[2])	
  rand.wss <- as.matrix(dim(x)[1]-1)*sum(apply(km.rand,2,var))	
  for (i in 2:n.lev) rand.wss[i] <- sum(kmeans(km.rand, centers=i)$withinss)	
  rand.wss <- as.matrix(rand.wss)	
  return(rand.wss)	
}	

k.2 <- function(x){	
  for (i in 1:250) {	
    r.1 <- k.2.rand(kdata)	
    rand.mat[,i] <- r.1}	
  return(rand.mat)	
}	

# Determine if the data data table has > or < 3 variables and call appropriate function above	
if (dim(kdata)[2] == 2) { rand.mat <- k.2(kdata) } else { rand.mat <- k.1(kdata) }	

# Plot within groups SSE against all tested cluster solutions for actual and randomized data - 1st: Log scale, 2nd: Normal scale	

xrange <- range(1:n.lev)	
yrange <- range(log(rand.mat),log(wss))	
plot(xrange,yrange, type='n', xlab='Cluster Solution', ylab='Log of Within Group SSE', main='Cluster Solutions against Log of SSE')	
for (i in 1:250) lines(log(rand.mat[,i]),type='l',col='red')	
lines(log(wss), type="b", col='blue')	
legend('topright',c('Actual Data', '250 Random Runs'), col=c('blue', 'red'), lty=1)	

yrange <- range(rand.mat,wss)	
plot(xrange,yrange, type='n', xlab="Cluster Solution", ylab="Within Groups SSE", main="Cluster Solutions against SSE")	
for (i in 1:250) lines(rand.mat[,i],type='l',col='red')	
lines(1:n.lev, wss, type="b", col='blue')	
legend('topright',c('Actual Data', '250 Random Runs'), col=c('blue', 'red'), lty=1)	

# Calculate the mean and standard deviation of difference between SSE of actual data and SSE of 250 randomized datasets	
r.sse <- matrix(0,dim(rand.mat)[1],dim(rand.mat)[2])	
wss.1 <- as.matrix(wss)	
for (i in 1:dim(r.sse)[2]) {	
  r.temp <- abs(rand.mat[,i]-wss.1[,1])	
  r.sse[,i] <- r.temp}	
r.sse.m <- apply(r.sse,1,mean)	
r.sse.sd <- apply(r.sse,1,sd)	
r.sse.plus <- r.sse.m + r.sse.sd	
r.sse.min <- r.sse.m - r.sse.sd	

# Plot differeince between actual SSE mean SSE from 250 randomized datasets - 1st: Log scale, 2nd: Normal scale 	

xrange <- range(1:n.lev)	
yrange <- range(log(r.sse.plus),log(r.sse.min))	
plot(xrange,yrange, type='n',xlab='Cluster Solution', ylab='Log of SSE - Random SSE', main='Cluster Solustions against (Log of SSE - Random SSE)')	
lines(log(r.sse.m), type="b", col='blue')	
lines(log(r.sse.plus), type='l', col='red')	
lines(log(r.sse.min), type='l', col='red')	
legend('topright',c('SSE - random SSE', 'SD of SSE-random SSE'), col=c('blue', 'red'), lty=1)	

xrange <- range(1:n.lev)	
yrange <- range(r.sse.plus,r.sse.min)	
plot(xrange,yrange, type='n',xlab='Cluster Solution', ylab='SSE - Random SSE', main='Cluster Solutions against (SSE - Random SSE)')	
lines(r.sse.m, type="b", col='blue')	
lines(r.sse.plus, type='l', col='red')	
lines(r.sse.min, type='l', col='red')	
legend('topright',c('SSE - random SSE', 'SD of SSE-random SSE'), col=c('blue', 'red'), lty=1)	

# Ask for user input - Select the appropriate number of clusters	
#choose.clust <- function(){readline("What clustering solution would you like to use? ")} 	
#clust.level <- as.integer(choose.clust())	
clust.level <- 6	

# Apply K-means cluster solutions - append clusters to CSV file	
fit <- kmeans(kdata, clust.level)	
aggregate(kdata, by=list(fit$cluster), FUN=mean)	
clust.out <- fit$cluster	
kclust <- as.matrix(clust.out)	
kclust.out <- cbind(kclust, WBscale)	
write.table(kclust.out, file="kmeans_out.csv", sep=",")	

# Display Principal Components plot of data with clusters identified	

clusplot(kdata, fit$cluster, shade=F, labels=2, lines=0, color=T, lty=4, main='Principal Components plot showing K-means clusters')	


#Make plot of five cluster solution in space desginated by first two	
#  two discriminant functions	

plotcluster(kdata, fit$cluster, main="Six Cluster Solution in DA Space",	
            xlab="First Discriminant Function", ylab="Second Discriminant Function")	


#Just try twelve clusters to see how this works	
#  Centers gives the number of clusters desired.  	
#  You can either give a vector with the original centers, OR just specify the number of clusters.	
km1 <- kmeans(WBscale, centers = 12)	
km1	

#see which Species are in each cluster	
for (i in 1:12){	
  print(paste("Species in Cluster ", i))	
  print(WB$Species_Name[km1$cluster == i])	
  print (" ")	
}	

# Get membership and evaluate number of clusters.	

#Get plot for Euclidean, Ward. D again because it is the best

#get the distance matrix	
dist1 <- dist(WBscale, method = "euclidean")	

#now do clustering use WARDs method	
clust1 <- hclust(dist1, method = "ward.D")	

#draw the dendrogram	
plot(clust1,labels = WB[, 1], cex = 0.5, xlab = "Species (Euclidean, Ward.D)", ylab = "Distance", main = "Clustering for Mammal Species Data")	
rect.hclust(clust1, k = 6)	

# end of script	
